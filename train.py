from Dataset import DistortionDataset
from UNet import DistortionCorrectionNet
from utils import Evaluate, visualize_result
import torch
from torch.utils.data import DataLoader
import torch.optim as optim
import numpy as np
import random
import os

# âœ… å¹³æ»‘çº¦æŸå‡½æ•°ï¼ˆåŠ åœ¨ loss ä¸Šï¼‰
def flow_smoothness_loss(flow):
    dx = torch.abs(flow[:, :, :, :-1] - flow[:, :, :, 1:])
    dy = torch.abs(flow[:, :, :-1, :] - flow[:, :, 1:, :])
    return dx.mean() + dy.mean()

if __name__ == "__main__":
    # âœ… è®¾ç½®éšæœºç§å­ä»¥å¢å¼ºå¤ç°æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)

    # è®¾å¤‡é€‰æ‹©
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åˆå§‹åŒ–æ¨¡å‹å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    model = DistortionCorrectionNet().to(device)

    # âœ… å¦‚æœå­˜åœ¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™åŠ è½½å®ƒï¼ˆé¿å…é‡å¤è®­ç»ƒï¼‰
    pretrained_path = "pretrained_chess.pth"
    if os.path.exists(pretrained_path):
        model.load_state_dict(torch.load(pretrained_path, map_location=device))
        print("âœ… å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡ pretrained_chess.pth")

    # ä½ è¿˜éœ€è¦å®šä¹‰ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ç­‰
    smoothness_weight = 0.1  # å¯æ ¹æ®éœ€è¦è°ƒæ•´
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    # åŠ è½½æ•°æ®é›†ï¼ˆè¯·æ ¹æ®ä½ çš„æ•°æ®é›†è·¯å¾„å’Œå‚æ•°è¿›è¡Œè°ƒæ•´ï¼‰
    chess_dataset = DistortionDataset(raw_dir="output_chess/raw", distorted_dir="output_chess/distorted")
    real_dataset = DistortionDataset(raw_dir="output_images/raw", distorted_dir="output_images/distorted")

    chess_loader = DataLoader(chess_dataset, batch_size=8, shuffle=True)
    real_loader = DataLoader(real_dataset, batch_size=8, shuffle=True)

    pretrain_success = True  # âœ… ç”¨äºåˆ¤æ–­æ˜¯å¦ç»§ç»­ finetune

    # é¢„è®­ç»ƒå’Œå¾®è°ƒçš„ epoch æ•°é‡
    pretrain_epochs = 50  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
    finetune_epochs = 30  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´

    # ---------------------
    # âœ… ç¬¬ä¸€é˜¶æ®µï¼šæ£‹ç›˜æ ¼é¢„è®­ç»ƒ
    # ---------------------
    for epoch in range(1, pretrain_epochs + 1):
        model.train()
        total_loss = 0.0

        try:
            for batch in chess_loader:
                distorted = batch['distorted'].to(device)
                target = batch['target'].to(device)

                output, flow = model(distorted)
                recon_loss = torch.nn.functional.l1_loss(output, target)
                smooth_loss = flow_smoothness_loss(flow)
                loss = recon_loss + smoothness_weight * smooth_loss

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

        except Exception as e:
            print(f"âŒ [é¢„è®­ç»ƒé˜¶æ®µé”™è¯¯] Epoch {epoch}: {e}")
            pretrain_success = False
            break

        avg_loss = total_loss / len(chess_loader)
        print(f"[é¢„è®­ç»ƒ Epoch {epoch}] Loss: {avg_loss:.4f}")

        if epoch % 10 == 0:
            try:
                Evaluate(model, chess_loader, device)
                visualize_result(model, chess_dataset, device, idx=0)
            except Exception as e:
                print(f"âš ï¸ [é¢„è®­ç»ƒè¯„ä¼°é”™è¯¯] Epoch {epoch}: {e}")
                pretrain_success = False
                break
        
        # âœ… ç¬¬ä¸€é˜¶æ®µè®­ç»ƒå®Œæˆåï¼ˆç¡®è®¤ successï¼‰ä¿å­˜ä¸€æ¬¡
        if pretrain_success:
            torch.save(model.state_dict(), "pretrained_chess.pth")
            print("âœ… å·²ä¿å­˜é¢„è®­ç»ƒæ¨¡å‹ä¸º pretrained_chess.pth")

    # ---------------------
    # âœ… ç¬¬äºŒé˜¶æ®µï¼šçœŸå®å›¾åƒå¾®è°ƒï¼ˆä»…åœ¨æˆåŠŸé¢„è®­ç»ƒåï¼‰
    # ---------------------
    # ---------------------
    # âœ… ç¬¬äºŒé˜¶æ®µï¼šçœŸå®å›¾åƒå¾®è°ƒï¼ˆä»…åœ¨æˆåŠŸé¢„è®­ç»ƒåï¼‰
    # ---------------------
    finetuned_path = "distortion_correction.pth"

    if pretrain_success:
        if os.path.exists(finetuned_path):
            print("ğŸš« æ£€æµ‹åˆ°å·²æœ‰å¾®è°ƒæ¨¡å‹ distortion_correction.pthï¼Œè·³è¿‡å¾®è°ƒé˜¶æ®µ")
        else:
            for epoch in range(1, finetune_epochs + 1):
                model.train()
                total_loss = 0.0
                ...
            torch.save(model.state_dict(), finetuned_path)
            print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º distortion_correction.pth")

            model.train()
            total_loss = 0.0

            for batch in real_loader:
                distorted = batch['distorted'].to(device)
                target = batch['target'].to(device)

                output, flow = model(distorted)
                recon_loss = torch.nn.functional.l1_loss(output, target)
                smooth_loss = flow_smoothness_loss(flow)
                loss = recon_loss + smoothness_weight * smooth_loss

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()

            print(f"[Finetune Epoch {epoch}] Loss: {total_loss / len(real_loader):.4f}")

            if epoch % 10 == 0:
                try:
                    Evaluate(model, real_loader, device)
                    visualize_result(model, real_dataset, device, idx=0)
                except Exception as e:
                    print(f"âš ï¸ [å¾®è°ƒè¯„ä¼°é”™è¯¯] Epoch {epoch}: {e}")
                    # break  # Removed because break is invalid here; optionally use 'return' or 'continue' if inside a function or loop

        # âœ… ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), "distortion_correction.pth")
        print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º distortion_correction.pth")
    else:
        print("ğŸš« è·³è¿‡å¾®è°ƒé˜¶æ®µï¼Œå› ä¸ºé¢„è®­ç»ƒæœªæˆåŠŸå®Œæˆ")